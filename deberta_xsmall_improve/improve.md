# DeBERTa モデル MAP@3 スコア改善提案

## 現状
- **現在のMAP@3スコア**: 0.9301
- **使用モデル**: deberta-v3-xsmall
- **主要設定**:
  - エポック数: 30
  - 学習率: 5e-5
  - バッチサイズ: 32
  - 最大トークン長: 256

## 改善提案

### 1. ハイパーパラメータの調整

#### 1.1 学習率の最適化
- **現在**: 5e-5
- **提案**:
  - 3e-5 (より安定した学習)
  - 2e-5 (より慎重な学習)
- **理由**: 学習率を下げることで、より細かな重みの調整が可能になり、局所最適解を避けやすくなる

#### 1.2 エポック数の増加
- **現在**: 30
- **提案**: 40-50
- **注意点**: Early Stoppingが実装されていないため、過学習に注意が必要

#### 1.3 バッチサイズの調整
- **現在**: 32
- **提案**: 16
- **理由**: より頻繁な重み更新により、学習の精度が向上する可能性

### 2. モデルアーキテクチャの改善

#### 2.1 より大きなモデルの使用
- **現在**: deberta-v3-xsmall
- **提案**:
  - deberta-v3-small (パラメータ数: 約2倍)
  - deberta-v3-base (パラメータ数: 約10倍)
- **トレードオフ**: 精度向上 vs 学習時間・メモリ使用量の増加

#### 2.2 最大トークン長の拡張
- **現在**: 256
- **提案**: 384 または 512
- **理由**: より多くのコンテキスト情報を活用できる（特に長い問題文や解答の場合）

### 3. 学習戦略の改善

#### 3.1 学習率スケジューラーの導入
```python
# TrainingArgumentsに追加
warmup_steps=500,  # または warmup_ratio=0.1
lr_scheduler_type="cosine",  # または "linear"
```

#### 3.2 正則化の強化
```python
# TrainingArgumentsに追加
weight_decay=0.01,
gradient_checkpointing=True,
```

#### 3.3 Gradient Accumulation
```python
# TrainingArgumentsに追加
gradient_accumulation_steps=2,  # 実効的なバッチサイズを2倍に
```

### 4. データ拡張・前処理の改善

#### 4.1 クラス不均衡への対処
- クラスごとのサンプル数を分析
- 少数クラスに対する重み付けまたはオーバーサンプリング
- Focal Lossなどの不均衡に強い損失関数の使用

#### 4.2 データ拡張手法
- パラフレーズ生成
- 同義語置換
- 問題文の言い換え

#### 4.3 特徴量エンジニアリングの拡張
- 問題の難易度スコアの追加
- カテゴリ情報のより詳細な活用
- 正答率情報の組み込み

### 5. 評価・保存戦略の改善

#### 5.1 Early Stoppingの実装
```python
# TrainingArgumentsに追加
load_best_model_at_end=True,
early_stopping_patience=3,
```

#### 5.2 より頻繁な評価
```python
# 現在の設定
EVAL_STEPS = 200
# 提案
EVAL_STEPS = 100  # より頻繁に評価
```

#### 5.3 アンサンブル学習
- 異なるシードで複数モデルを学習
- 予測結果の平均化または投票

### 6. 推奨される実装順序

1. **第1段階** (低リスク・即効性):→実装済み
   - 学習率を3e-5に変更
   - weight_decayを0.01に設定
   - warmup_stepsを追加

2. **第2段階** (中リスク・高効果):
   - MAX_LENを384に拡張
   - バッチサイズを16に変更
   - gradient_accumulation_steps=2を設定

3. **第3段階** (高リスク・最大効果):
   - モデルをdeberta-v3-smallに変更
   - エポック数を40に増加
   - Early Stoppingの実装

### 7. 実験管理の提案

各変更を個別に実験し、効果を測定することを推奨：

```python
# config.pyに実験設定を追加
EXPERIMENT_NAME = "baseline"  # または "lr_3e-5", "model_small" など
OUTPUT_DIR = f"ver_{VER}_{EXPERIMENT_NAME}"
```

### 8. 注意事項

- 各変更は独立して効果を確認すること
- 計算リソースの制約を考慮すること
- 過学習の兆候（学習損失は下がるが検証損失が上がる）に注意
- MAP@3スコアの小さな改善でも有意義（0.93 → 0.935 = 0.5%向上）

## まとめ

最も効果的と予想される改善策：
1. **学習率の調整** (3e-5)
2. **weight_decayの追加** (0.01)
3. **MAX_LENの拡張** (384)
4. **より大きなモデル** (deberta-v3-small)

これらの変更により、MAP@3スコアを0.935-0.940程度まで向上させることが期待できます。
