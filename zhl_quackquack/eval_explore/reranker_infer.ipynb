{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b4e98de-9dbd-4aaf-88e7-858b262cfd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2af70682-bc62-4627-ab5b-52b96245ca6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/main/lib/python3.12/site-packages/sklearn/base.py:440: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.6.0 when using version 1.7.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "TARGET_SUB = \"./qwen3_eval_fold3.csv\"\n",
    "RERANKER_PATH = \"./v2/lgbm_ranker_f3.pkl\"\n",
    "le = joblib.load(\"./label_encoder.joblib\")\n",
    "TOP_K = 3\n",
    "FOLD_IDX = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1a5813-1cc5-4330-b38c-e2ef75cb8fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_topk(df_bgm, ranker, le, k=3):\n",
    "    # Build candidate table in batch (no labels needed)\n",
    "    rows = []\n",
    "    for idx, row in df_bgm.iterrows():\n",
    "        for class_name in le.classes_:\n",
    "            rows.append({\n",
    "                \"qid\": row[\"row_id\"],\n",
    "                \"QuestionId\": row[\"QuestionId\"],\n",
    "                \"is_correct\": row[\"is_correct\"],\n",
    "                \"candidate\": class_name,\n",
    "                \"rank_feature\": row[f\"{class_name}_rank\"],\n",
    "                \"prob_feature\": row[f\"{class_name}_prob\"],\n",
    "            })\n",
    "    cand_df = pd.DataFrame(rows)\n",
    "\n",
    "    # Cast categorical if needed\n",
    "    cand_df[\"QuestionId\"] = cand_df[\"QuestionId\"].astype(\"category\")\n",
    "    cand_df[\"candidate\"] = cand_df[\"candidate\"].astype(\"category\")\n",
    "\n",
    "    # Predict in one shot\n",
    "    features = [\"QuestionId\", \"candidate\", \"is_correct\", \"rank_feature\", \"prob_feature\"]\n",
    "    # features = [\"QuestionId\", \"candidate\", \"is_correct\", \"prob_feature\"]\n",
    "    cand_df[\"score\"] = ranker.predict(cand_df[features])\n",
    "\n",
    "    # For each query, sort by score and take top-k\n",
    "    topk_df = (\n",
    "        cand_df.sort_values([\"qid\", \"score\"], ascending=[True, False])\n",
    "               .groupby(\"qid\")[\"candidate\"].apply(lambda s: list(s.head(k)))\n",
    "    )\n",
    "    \n",
    "    result_df = (\n",
    "        df_bgm[[\"row_id\", \"is_correct\"]]\n",
    "        .merge(topk_df, left_on=\"row_id\", right_on=\"qid\", how=\"left\")\n",
    "    )\n",
    "\n",
    "    return result_df\n",
    "\n",
    "df_target = pd.read_csv(TARGET_SUB)\n",
    "\n",
    "# Comment later\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "df_target[\"Misconception\"] = df_target[\"Misconception\"].fillna(\"NA\")\n",
    "df_target[\"misconception_target\"] = df_target[\"Category\"].apply(lambda x: x.split(\"_\")[-1]+\":\") + df_target[\"Misconception\"]\n",
    "df_target[\"split_key\"] = (df_target['QuestionId'].astype(str) + \"_\" + df_target['misconception_target'].astype(str)).astype('category').cat.codes\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "fold_indices = list(skf.split(df_target, df_target['split_key']))\n",
    "tr_idx, va_idx = fold_indices[FOLD_IDX]\n",
    "df_tr, df_va = df_target.iloc[tr_idx].copy(), df_target.iloc[va_idx].copy()\n",
    "df_target = df_tr.copy()\n",
    "df_target = df_target.sample(frac=1, random_state=42) \n",
    "# comment above later\n",
    "\n",
    "df_target = df_target[[\"row_id\", \"QuestionId\", \"is_correct\", \"Pred_Targets\", \"Corresponding Probs\"]]\n",
    "df_target[\"Pred_Targets_list\"] = df_target[\"Pred_Targets\"].str.split(\"|\")\n",
    "df_target[\"Pred_Probs_list\"] = df_target[\"Corresponding Probs\"].str.split(\"|\").apply(lambda x: [float(p) for p in x])\n",
    "for class_name in le.classes_:\n",
    "    df_target[f\"{class_name}_rank\"] = df_target.apply(lambda x: x[\"Pred_Targets_list\"].index(class_name), axis=1)\n",
    "    df_target[f\"{class_name}_prob\"] = df_target.apply(lambda x: x[\"Pred_Probs_list\"][x[f\"{class_name}_rank\"]], axis=1)\n",
    "\n",
    "ranker = joblib.load(RERANKER_PATH)\n",
    "df_target = predict_topk(df_target, ranker, le, k=TOP_K)\n",
    "\n",
    "def add_prefix(lbl, flag):\n",
    "    prefix = \"True_\" if int(flag) == 1 else \"False_\"\n",
    "    # lbl is like \"Algebra:Mis-X\"\n",
    "    return f\"{prefix}{lbl}\"\n",
    "    \n",
    "is_corr = df_target['is_correct'].astype(int).values  # 1 or 0\n",
    "df_target[\"Category:Misconception\"] = df_target.apply(lambda x: ' '.join([ add_prefix(tmp, x['is_correct']) for tmp in x[\"candidate\"] ]), axis=1)\n",
    "df_target = df_target[[\"row_id\", \"Category:Misconception\"]].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf9e25a-fde9-43e2-9352-0a4cfca3758d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046b9733-c517-49c3-8aeb-b05531207d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = df_tr.merge(df_target, on=\"row_id\", how=\"left\")\n",
    "gtruth = final[\"Category\"] + \":\" + final[\"Misconception\"].fillna(\"NA\")\n",
    "pred = final[\"Category:Misconception\"].apply(lambda x: x.split(\" \"))\n",
    "def mapk(actual, predicted, k=3):\n",
    "    score = 0.0\n",
    "    for a, p in zip(actual, predicted):\n",
    "        try:\n",
    "            idx = p[:k].index(a)\n",
    "            score += 1.0 / (idx + 1)\n",
    "        except ValueError:\n",
    "            continue\n",
    "    return score / len(actual)\n",
    "\n",
    "mapk(gtruth, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57aaf07-572b-4799-ba99-5bddd6bb52eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
