#!/bin/bash
set -euo pipefail

# 8 张卡一一对应
gpus=(0 1 2 3 4 5 6 7)

# version 固定为 1..8（你也可以手动改）
vers=(17 18 19 20 21 22 23 24)

# 下面四个数组请按你的“允许的组合”填好，每个长度都必须是 8
models=("Qwen/Qwen3-4B-Instruct-2507" "Qwen/Qwen3-4B-Instruct-2507" "Qwen/Qwen3-4B-Instruct-2507" "Qwen/Qwen3-4B-Instruct-2507" "Qwen/Qwen3-4B-Instruct-2507" "Qwen/Qwen3-4B-Instruct-2507" "Qwen/Qwen3-4B-Instruct-2507" "Qwen/Qwen3-4B-Instruct-2507")

rs=(16 16 16 16 16 16 16 16)
mids=(0.9 0.9 0.9 0.9 0.7 0.7 0.9 0.7)
ends=(0.1 0.1 0.1 0.1 0.3 0.3 0.3 0.1)

# new arrays
dropouts=(0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05)
entropy_temperatures=(1 2 5 2 1 3 2 2)
warmup_fracs=(0.5 0.5 0.5 0.1 0.5 0.5 0.3 0.5)

# 长度校验
n=${#vers[@]}
if [[ $n -ne 8 || $n -ne ${#gpus[@]} || $n -ne ${#models[@]} || \
      $n -ne ${#rs[@]} || $n -ne ${#mids[@]} || $n -ne ${#ends[@]} || \
      $n -ne ${#dropouts[@]} || $n -ne ${#warmup_fracs[@]} ]]; then
  echo "数组长度不一致或不是 8，请检查！"
  exit 1
fi

mkdir -p logs configs

for ((i=0; i<8; i++)); do
  gpu=${gpus[$i]}
  ver=${vers[$i]}
  model=${models[$i]}
  r=${rs[$i]}
  mid=${mids[$i]}
  end=${ends[$i]}
  dropout=${dropouts[$i]}
  entropy_temperature=${entropy_temperatures[$i]}
  warmup_frac=${warmup_fracs[$i]}

  short_model=$(basename "$model")
  log_file="logs/ver${ver}_r${r}_${short_model}_mid${mid}_end${end}.log"
  cfg_file="configs/ver${ver}_r${r}_${short_model}_mid${mid}_end${end}.txt"

  echo "Launching: GPU=$gpu ver=$ver r=$r model=$model mid=$mid end=$end warmup_frac=$warmup_frac"
  echo " -> log: $log_file"
  echo " -> cfg: $cfg_file"

  cat > "$cfg_file" <<EOF
ver: $ver
model_name: $model
max_len: 300
cv_fold: 5
cv_seed: 42
r: $r
lora_alpha: 32
lr: 2.5e-4
dropout: $dropout
epochs: 2
lr_scheduler: linear
beta_scheduler: adaptive
start: 1.0
mid: $mid
end: $end
warmup_frac: $warmup_frac
gpu: $gpu
entropy_temperature: $entropy_temperature
EOF

  CUDA_VISIBLE_DEVICES=$gpu python code_v1.py \
    --ver "$ver" \
    --model_name "$model" \
    --max_len 300 \
    --cv_fold 5 \
    --cv_seed 42 \
    --r "$r" \
    --lora_alpha 32 \
    --lr 2.5e-4 \
    --dropout "$dropout" \
    --epochs 2 \
    --lr_scheduler linear \
    --beta_scheduler adaptive \
    --start 1.0 \
    --mid "$mid" \
    --end "$end" \
    --warmup_frac "$warmup_frac" \
    --entropy_temperature "$entropy_temperature" \
    > "$log_file" 2>&1 &
done

wait
echo "全部 8 个任务已完成启动；日志在 ./logs，配置在 ./configs"
