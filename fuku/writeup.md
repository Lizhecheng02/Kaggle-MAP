コンペ参加初日，XGBoostを用いて分類を行ったところ，0.9に近い数字が出せた．それでノートブックを公開した．
分類タスクではあるが，最終的にはBERTもしくは，LLMを用いての解法でよい精度が出ると考えていた．
ModernBERT, debertaなどのノートブックが公開される中，自分はQwen3-0.6bを用いて実験を行っていた．
Debertaのノートブックで利用されているモデルの大きさを変更したところ，モデルが大きければ大きいほど高いスコアが出せることに気が付く．
Ettin-encoder-1bのノートブックが公開される．この時点で，Qwen3-0.6bでは，0.935程度のスコアしか出せていなかった記憶．
それまでは，選択肢をすべてLLMに与えて，分類をさせていたが，Ettinのノートブックを見るとかなりシンプルだった．シンプルなプロンプトのほうがより良いスコアが出せると考え，Qwen3のプロンプトをかなりシンプルなものへ変更した．それによりスコア+0.01くらい．
Chrisの公開ノートブックでGemma2で0.942のノートブックが公開される．この時点で，Gemma3-12bで実験をしており，CV0.948が出せていたが，提出が何回やっても成功せず断念．Qwen3-4bでは0.944を出していた．しかし，このノートブックのプロンプトを見て改善することにより，0.001程度のスコア向上．
CVを少なくすることによってフルトレーニングの開始．これにより，CV0.001程度改善することが確認できた．
モデルは大きくなればなるほど学習が遅くなるので，0.6bでテストし，よい設定があれば，その設定，プロンプトで，Qwen3-14bを訓練した．モデルを大きくすることにより，0.945程度出せた．
LoRAの設定を，16/32をずっと使っていたところ，LoRAのRankを変更することにより，0.002程度の改善が行えた．Qwenにおける最善の設定は，64/128だった．モデルにより大きさは異なると考えられる．
LLMリーダーボードを閲覧し，Phi4の性能が高いことに気が付く．
Phi4を利用して0.948を達成した．Reasoning-plusのほうが性能がよさそうだが，今のところPhi-4のほうがスコアが高い．
アンサンブルにより，0.950
LLMはシステムプロンプトで数学の専門家ですねとか，ほめたほうが良い成果を残す．
