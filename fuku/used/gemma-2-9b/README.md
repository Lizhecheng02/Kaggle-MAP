  - linear: 学習率を線形に0まで減衰。短〜中規模の微調整で安定。
  - cosine_with_restarts: 余弦減衰にリスタート。局所解からの脱出や長期訓練に有効。
  - polynomial: 多項式減衰（終端LRやpowerを設定可能）。長い収束期を持たせたいとき。
  - constant: 一定LR（ウォームアップ0のとき）。学習が安定している/LoRAで小LR固定に。
  - constant_with_warmup: ウォームアップ後に一定LR。小規模データの過学習を避けつつ安定させたいとき。
  - inverse_sqrt: Transformer系で用いられるNoam型。ウォームアップ後に1/√stepで減衰。
  - reduce_on_plateau: 評価指標が停滞したらLRを段階的に下げる。早期収束/過学習抑制に有効（評価を定期実行している前提）。
