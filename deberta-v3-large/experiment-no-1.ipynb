{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T06:23:32.022101Z",
     "iopub.status.busy": "2025-07-14T06:23:32.021827Z",
     "iopub.status.idle": "2025-07-14T06:23:32.028919Z",
     "shell.execute_reply": "2025-07-14T06:23:32.028448Z",
     "shell.execute_reply.started": "2025-07-14T06:23:32.022079Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "VER=1\n",
    "#model_name = \"/kaggle/input/huggingfacedebertav3variants/deberta-v3-xsmall\"\n",
    "#model_name = '/kaggle/input/huggingfacedebertav3variants/deberta-v3-small'\n",
    "#model_name = '/kaggle/input/huggingfacedebertav3variants/deberta-v3-base'\n",
    "#model_name = '/kaggle/input/huggingfacedebertav3variants/deberta-v3-large'\n",
    "model_name = \"/root/kaggle/map-charting-student-math-misunderstandings/models/deberta-v3-large\"\n",
    "EPOCHS = 4\n",
    "\n",
    "DIR = f\"ver_{VER}\"\n",
    "os.makedirs(DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T06:23:32.306972Z",
     "iopub.status.busy": "2025-07-14T06:23:32.306779Z",
     "iopub.status.idle": "2025-07-14T06:23:33.619252Z",
     "shell.execute_reply": "2025-07-14T06:23:33.618672Z",
     "shell.execute_reply.started": "2025-07-14T06:23:32.306956Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "train = pd.read_csv('/kaggle/input/map-charting-student-math-misunderstandings/train.csv')\n",
    "train.Misconception = train.Misconception.fillna('NA')\n",
    "train['target'] = train.Category+\":\"+train.Misconception\n",
    "train['label'] = le.fit_transform(train['target'])\n",
    "n_classes = len(le.classes_)\n",
    "\n",
    "import re\n",
    "\n",
    "# Enhanced feature extraction\n",
    "train['explanation_len'] = train['StudentExplanation'].fillna('').apply(len)\n",
    "train['mc_frac_count'] = train['StudentExplanation'].fillna('').apply(\n",
    "    lambda x: len(re.findall(r'FRAC_\\d+_\\d+|\\\\frac', x))\n",
    ")\n",
    "train['number_count'] = train['StudentExplanation'].fillna('').apply(\n",
    "    lambda x: len(re.findall(r'\\b\\d+\\b', x))\n",
    ")\n",
    "train['operator_count'] = train['StudentExplanation'].fillna('').apply(\n",
    "    lambda x: len(re.findall(r'[\\+\\-\\*/=]', x))\n",
    ")\n",
    "train['mc_answer_len'] = train['MC_Answer'].fillna('').apply(len)\n",
    "train['question_len'] = train['QuestionText'].fillna('').apply(len)\n",
    "train['explanation_to_question_ratio'] = train['explanation_len'] / (train['question_len'] + 1)\n",
    "\n",
    "print(f\"Train shape: {train.shape} with {n_classes} target classes\")\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T06:03:24.019142Z",
     "iopub.status.busy": "2025-07-14T06:03:24.018326Z",
     "iopub.status.idle": "2025-07-14T06:03:24.328318Z",
     "shell.execute_reply": "2025-07-14T06:03:24.327785Z",
     "shell.execute_reply.started": "2025-07-14T06:03:24.019104Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "idx = train.apply(lambda row: row.Category.split('_')[0],axis=1)=='True'\n",
    "correct = train.loc[idx].copy()\n",
    "correct['c'] = correct.groupby(['QuestionId','MC_Answer']).MC_Answer.transform('count')\n",
    "correct = correct.sort_values('c',ascending=False)\n",
    "correct = correct.drop_duplicates(['QuestionId'])\n",
    "correct = correct[['QuestionId','MC_Answer']]\n",
    "correct['is_correct'] = 1\n",
    "\n",
    "train = train.merge(correct, on=['QuestionId','MC_Answer'], how='left')\n",
    "train.is_correct = train.is_correct.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T06:03:24.390913Z",
     "iopub.status.busy": "2025-07-14T06:03:24.390691Z",
     "iopub.status.idle": "2025-07-14T06:03:24.473671Z",
     "shell.execute_reply": "2025-07-14T06:03:24.473067Z",
     "shell.execute_reply.started": "2025-07-14T06:03:24.390896Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Math, Latex\n",
    "\n",
    "# GET ANSWER CHOICES\n",
    "tmp = train.groupby(['QuestionId','MC_Answer']).size().reset_index(name='count')\n",
    "tmp['rank'] = tmp.groupby('QuestionId')['count'].rank(method='dense', ascending=False).astype(int) - 1\n",
    "tmp = tmp.drop('count',axis=1)\n",
    "tmp = tmp.sort_values(['QuestionId','rank'])\n",
    "\n",
    "# DISPLAY QUESTION AND ANSWER CHOICES\n",
    "Q = tmp.QuestionId.unique()\n",
    "for q in Q:\n",
    "    question = train.loc[train.QuestionId==q].iloc[0].QuestionText\n",
    "    choices = tmp.loc[tmp.QuestionId==q].MC_Answer.values\n",
    "    labels=\"ABCD\"\n",
    "    choice_str = \" \".join([f\"({labels[i]}) {choice}\" for i, choice in enumerate(choices)])\n",
    "\n",
    "    print()\n",
    "    display(Latex(f\"QuestionId {q}: {question}\") )\n",
    "    display(Latex(f\"MC Answers: {choice_str}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T06:06:32.869994Z",
     "iopub.status.busy": "2025-07-14T06:06:32.869733Z",
     "iopub.status.idle": "2025-07-14T06:07:00.761608Z",
     "shell.execute_reply": "2025-07-14T06:07:00.761036Z",
     "shell.execute_reply.started": "2025-07-14T06:06:32.869978Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import DebertaTokenizer, DebertaForSequenceClassification, TrainingArguments, Trainer\n",
    "from transformers import AutoTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "import numpy as np\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "MAX_LEN = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T06:07:02.365251Z",
     "iopub.status.busy": "2025-07-14T06:07:02.364273Z",
     "iopub.status.idle": "2025-07-14T06:07:02.844342Z",
     "shell.execute_reply": "2025-07-14T06:07:02.843742Z",
     "shell.execute_reply.started": "2025-07-14T06:07:02.365226Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def format_input(row):\n",
    "    x = \"This answer is correct.\"\n",
    "    if not row['is_correct']:\n",
    "        x = \"This answer is incorrect.\"\n",
    "\n",
    "    extra = (\n",
    "        f\"Additional Info: \"\n",
    "        f\"The explanation has {row['explanation_len']} characters \"\n",
    "        f\"and includes {row['mc_frac_count']} fraction(s).\"\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        f\"Question: {row['QuestionText']}\\n\"\n",
    "        f\"Answer: {row['MC_Answer']}\\n\"\n",
    "        f\"{x}\\n\"\n",
    "        f\"Student Explanation: {row['StudentExplanation']}\\n\"\n",
    "        f\"{extra}\"\n",
    "    )\n",
    "\n",
    "train['text'] = train.apply(format_input,axis=1)\n",
    "print(\"Example prompt for our LLM:\")\n",
    "print()\n",
    "print( train.text.values[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T06:07:02.96307Z",
     "iopub.status.busy": "2025-07-14T06:07:02.962867Z",
     "iopub.status.idle": "2025-07-14T06:07:09.866396Z",
     "shell.execute_reply": "2025-07-14T06:07:09.865653Z",
     "shell.execute_reply.started": "2025-07-14T06:07:02.963053Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "lengths = [len(tokenizer.encode(t, truncation=False)) for t in train[\"text\"]]\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(lengths, bins=50)\n",
    "plt.title(\"Token Length Distribution\")\n",
    "plt.xlabel(\"Number of tokens\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T06:07:10.176924Z",
     "iopub.status.busy": "2025-07-14T06:07:10.176621Z",
     "iopub.status.idle": "2025-07-14T06:07:10.187113Z",
     "shell.execute_reply": "2025-07-14T06:07:10.186501Z",
     "shell.execute_reply.started": "2025-07-14T06:07:10.176906Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "L = (np.array(lengths)>MAX_LEN).sum()\n",
    "print(f\"There are {L} train sample(s) with more than {MAX_LEN} tokens\")\n",
    "np.sort( lengths )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T06:07:12.471579Z",
     "iopub.status.busy": "2025-07-14T06:07:12.47134Z",
     "iopub.status.idle": "2025-07-14T06:07:12.575119Z",
     "shell.execute_reply": "2025-07-14T06:07:12.574269Z",
     "shell.execute_reply.started": "2025-07-14T06:07:12.471564Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Split into train and validation sets\n",
    "train_df, val_df = train_test_split(train, test_size=0.05, random_state=42)\n",
    "\n",
    "# Convert to Hugging Face Dataset\n",
    "COLS = ['text','label']\n",
    "train_ds = Dataset.from_pandas(train_df[COLS])\n",
    "val_ds = Dataset.from_pandas(val_df[COLS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T05:04:30.011666Z",
     "iopub.status.busy": "2025-07-14T05:04:30.011448Z",
     "iopub.status.idle": "2025-07-14T05:04:37.833766Z",
     "shell.execute_reply": "2025-07-14T05:04:37.832945Z",
     "shell.execute_reply.started": "2025-07-14T05:04:30.01165Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Tokenization function\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True, max_length=256)\n",
    "\n",
    "train_ds = train_ds.map(tokenize, batched=True)\n",
    "val_ds = val_ds.map(tokenize, batched=True)\n",
    "\n",
    "# Set format for PyTorch\n",
    "columns = ['input_ids', 'attention_mask', 'label']\n",
    "train_ds.set_format(type='torch', columns=columns)\n",
    "val_ds.set_format(type='torch', columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T05:04:37.834668Z",
     "iopub.status.busy": "2025-07-14T05:04:37.834454Z",
     "iopub.status.idle": "2025-07-14T05:04:43.937213Z",
     "shell.execute_reply": "2025-07-14T05:04:43.936313Z",
     "shell.execute_reply.started": "2025-07-14T05:04:37.834643Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import DebertaV2ForSequenceClassification\n",
    "\n",
    "model = DebertaV2ForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=n_classes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T05:04:43.93879Z",
     "iopub.status.busy": "2025-07-14T05:04:43.93843Z",
     "iopub.status.idle": "2025-07-14T05:04:43.982605Z",
     "shell.execute_reply": "2025-07-14T05:04:43.981453Z",
     "shell.execute_reply.started": "2025-07-14T05:04:43.938744Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# training_args = TrainingArguments(\n",
    "#     output_dir = f\"./{DIR}\",\n",
    "#     do_train=True,\n",
    "#     do_eval=True,\n",
    "#     eval_strategy=\"steps\",\n",
    "#     save_strategy=\"steps\", #no for no saving\n",
    "#     num_train_epochs=EPOCHS,\n",
    "#     per_device_train_batch_size=16*2,\n",
    "#     per_device_eval_batch_size=32*2,\n",
    "#     learning_rate=5e-5,\n",
    "#     logging_dir=\"./logs\",\n",
    "#     logging_steps=50,\n",
    "#     save_steps=200,\n",
    "#     eval_steps=200,\n",
    "#     save_total_limit=1,\n",
    "#     metric_for_best_model=\"map@3\",\n",
    "#     greater_is_better=True,\n",
    "#     load_best_model_at_end=True,\n",
    "#     report_to=\"none\",\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"./{DIR}\",\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    eval_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    num_train_epochs=EPOCHS,\n",
    "\n",
    "    # Keep batch size small for memory\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    gradient_accumulation_steps=16,  # Simulates batch_size * 4\n",
    "\n",
    "\n",
    "    # Must enable mixed precision to reduce VRAM usage\n",
    "    #fp16=True,\n",
    "\n",
    "    learning_rate=5e-5,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=50,\n",
    "    save_steps=200,\n",
    "    eval_steps=200,\n",
    "    save_total_limit=1,\n",
    "    metric_for_best_model=\"map@3\",\n",
    "    greater_is_better=True,\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"none\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T05:04:43.983956Z",
     "iopub.status.busy": "2025-07-14T05:04:43.983647Z",
     "iopub.status.idle": "2025-07-14T05:04:44.01281Z",
     "shell.execute_reply": "2025-07-14T05:04:44.012101Z",
     "shell.execute_reply.started": "2025-07-14T05:04:43.983932Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# CUSTOM MAP@3 METRIC\n",
    "\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "def compute_map3(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    probs = torch.nn.functional.softmax(torch.tensor(logits), dim=-1).numpy()\n",
    "\n",
    "    top3 = np.argsort(-probs, axis=1)[:, :3]  # Top 3 predictions\n",
    "    match = (top3 == labels[:, None])\n",
    "\n",
    "    # Compute MAP@3 manually\n",
    "    map3 = 0\n",
    "    for i in range(len(labels)):\n",
    "        if match[i, 0]:\n",
    "            map3 += 1.0\n",
    "        elif match[i, 1]:\n",
    "            map3 += 1.0 / 2\n",
    "        elif match[i, 2]:\n",
    "            map3 += 1.0 / 3\n",
    "    return {\"map@3\": map3 / len(labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-07-14T05:58:17.723Z",
     "iopub.execute_input": "2025-07-14T05:04:44.013979Z",
     "iopub.status.busy": "2025-07-14T05:04:44.013683Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_map3,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-07-14T05:58:17.723Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "trainer.save_model(f\"{DIR}/best\")\n",
    "_ = joblib.dump(le, f\"{DIR}/label_encoder.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-07-14T05:58:17.723Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(f\"{DIR}/best\")\n",
    "model = DebertaV2ForSequenceClassification.from_pretrained(\n",
    "    f\"{DIR}/best\",\n",
    "    num_labels=n_classes\n",
    ")\n",
    "training_args = TrainingArguments(report_to=\"none\")\n",
    "trainer = Trainer(model=model, tokenizer=tokenizer, args=training_args)\n",
    "le = joblib.load(f\"{DIR}/label_encoder.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T06:23:42.342525Z",
     "iopub.status.busy": "2025-07-14T06:23:42.341805Z",
     "iopub.status.idle": "2025-07-14T06:23:42.356191Z",
     "shell.execute_reply": "2025-07-14T06:23:42.355484Z",
     "shell.execute_reply.started": "2025-07-14T06:23:42.3425Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('/kaggle/input/map-charting-student-math-misunderstandings/test.csv')\n",
    "print( test.shape )\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T06:23:44.157373Z",
     "iopub.status.busy": "2025-07-14T06:23:44.157092Z",
     "iopub.status.idle": "2025-07-14T06:23:44.167999Z",
     "shell.execute_reply": "2025-07-14T06:23:44.167241Z",
     "shell.execute_reply.started": "2025-07-14T06:23:44.157351Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Enhanced feature extraction for test set\n",
    "test['explanation_len'] = test['StudentExplanation'].fillna('').apply(len)\n",
    "test['mc_frac_count'] = test['StudentExplanation'].fillna('').apply(\n",
    "    lambda x: len(re.findall(r'FRAC_\\d+_\\d+|\\\\frac', x))\n",
    ")\n",
    "test['number_count'] = test['StudentExplanation'].fillna('').apply(\n",
    "    lambda x: len(re.findall(r'\\b\\d+\\b', x))\n",
    ")\n",
    "test['operator_count'] = test['StudentExplanation'].fillna('').apply(\n",
    "    lambda x: len(re.findall(r'[\\+\\-\\*/=]', x))\n",
    ")\n",
    "test['mc_answer_len'] = test['MC_Answer'].fillna('').apply(len)\n",
    "test['question_len'] = test['QuestionText'].fillna('').apply(len)\n",
    "test['explanation_to_question_ratio'] = test['explanation_len'] / (test['question_len'] + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T06:23:46.387239Z",
     "iopub.status.busy": "2025-07-14T06:23:46.386958Z",
     "iopub.status.idle": "2025-07-14T06:23:46.39701Z",
     "shell.execute_reply": "2025-07-14T06:23:46.396313Z",
     "shell.execute_reply.started": "2025-07-14T06:23:46.387217Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-07-14T05:58:17.724Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test = test.merge(correct, on=['QuestionId','MC_Answer'], how='left')\n",
    "test.is_correct = test.is_correct.fillna(0)\n",
    "\n",
    "\n",
    "\n",
    "test['text'] = test.apply(format_input,axis=1)\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-07-14T05:58:17.724Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "ds_test = Dataset.from_pandas(test[['text']])\n",
    "ds_test = ds_test.map(tokenize, batched=True)\n",
    "\n",
    "predictions = trainer.predict(ds_test)\n",
    "probs = torch.nn.functional.softmax(torch.tensor(predictions.predictions), dim=1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-07-14T05:58:17.724Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Get top 3 predicted class indices\n",
    "top3 = np.argsort(-probs, axis=1)[:, :3]   # shape: [num_samples, 3]\n",
    "\n",
    "# Decode numeric class indices to original string labels\n",
    "flat_top3 = top3.flatten()\n",
    "decoded_labels = le.inverse_transform(flat_top3)\n",
    "top3_labels = decoded_labels.reshape(top3.shape)\n",
    "\n",
    "# Join 3 labels per row with space\n",
    "joined_preds = [\" \".join(row) for row in top3_labels]\n",
    "\n",
    "# Save submission\n",
    "sub = pd.DataFrame({\n",
    "    \"row_id\": test.row_id.values,\n",
    "    \"Category:Misconception\": joined_preds\n",
    "})\n",
    "sub.to_csv(\"submission.csv\", index=False)\n",
    "sub.head()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 12957508,
     "sourceId": 104383,
     "sourceType": "competition"
    },
    {
     "datasetId": 2663421,
     "sourceId": 4620664,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "kaggle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
